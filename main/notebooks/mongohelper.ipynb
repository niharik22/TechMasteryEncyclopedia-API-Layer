{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "class MongoDBClient:\n",
    "    def __init__(self, uri: str, database_name: str, collection_name: str, test_mode: bool):\n",
    "        try:\n",
    "            self.client = MongoClient(uri)\n",
    "            self.test_mode = test_mode\n",
    "            if test_mode:\n",
    "                self.db = self.client['test_db']  # Use test database if in test mode\n",
    "            else:\n",
    "                self.db = self.client[database_name]  # Use production database\n",
    "            self.collection = self.db[collection_name]\n",
    "            logging.info(f\"Connected to MongoDB database: {self.db.name}, collection: {self.collection.name}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error connecting to MongoDB: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def make_index(self, index_fields) -> None:\n",
    "        \"\"\"\n",
    "        Creates an index on the specified fields in the collection.\n",
    "\n",
    "        Args:\n",
    "            index_fields (str or list): Field(s) for the index. Can be a single field as a string or multiple fields as a list of tuples.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # If a single string is passed, create a single field index\n",
    "            if isinstance(index_fields, str):\n",
    "                self.collection.create_index(index_fields, unique=True)\n",
    "                logging.info(f\"Index created on {index_fields}\")\n",
    "            # If a list of tuples is passed, create a compound index\n",
    "            elif isinstance(index_fields, list) and all(isinstance(field, tuple) for field in index_fields):\n",
    "                self.collection.create_index(index_fields, unique=True)\n",
    "                logging.info(f\"Compound index created on {index_fields}\")\n",
    "            else:\n",
    "                logging.error(\"Invalid index format. Provide a string or list of tuples for compound indexes.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating index: {e}\")\n",
    "\n",
    "\n",
    "    def insert_document(self, doc: dict, col_name: str = None) -> bool:\n",
    "        \"\"\"Inserts a document into the collection.\"\"\"\n",
    "        collection = self.collection if col_name is None else self.db[col_name]\n",
    "        try:\n",
    "            collection.insert_one(doc)\n",
    "            logging.info(f\"Document inserted into {collection.name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error inserting document: {e}\")\n",
    "            return False\n",
    "\n",
    "    def update_document(self, query: dict, update: dict, upsert: bool = True, col_name: str = None):\n",
    "        \"\"\"Updates or inserts a document based on the query.\"\"\"\n",
    "        collection = self.collection if col_name is None else self.db[col_name]\n",
    "        try:\n",
    "            collection.update_one(query, {'$set': update}, upsert=upsert)\n",
    "            logging.debug(f\"Document updated or inserted in {collection.name}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error updating document: {e}\")\n",
    "\n",
    "    def insert_documents(self, docs: List[Dict], col_name: str) -> bool:\n",
    "        \"\"\"Performs bulk insertion of documents into the specified collection.\"\"\"\n",
    "        collection = self.db[col_name]\n",
    "        if docs:\n",
    "            try:\n",
    "                collection.insert_many(docs)\n",
    "                logging.info(f\"Inserted {len(docs)} documents into {collection.name} in bulk.\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during bulk insertion into {collection.name}: {e}\")\n",
    "                return False\n",
    "        else:\n",
    "            logging.info(\"No documents to insert.\")\n",
    "            return False\n",
    "\n",
    "    def update_many_documents(self, query: dict, update: dict, col_name: str):\n",
    "        \"\"\"Updates multiple documents in the specified collection.\"\"\"\n",
    "        collection = self.db[col_name]\n",
    "        try:\n",
    "            result = collection.update_many(query, {'$set': update})\n",
    "            logging.info(f\"Updated {result.modified_count} documents in {collection.name}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error updating documents in {collection.name}: {e}\")\n",
    "\n",
    "    def query_documents(self, query: dict, projection: dict = None, col_name: str = None):\n",
    "        \"\"\"Queries documents from the collection.\"\"\"\n",
    "        collection = self.collection if col_name is None else self.db[col_name]\n",
    "        try:\n",
    "            results = collection.find(query, projection)\n",
    "            logging.debug(f\"Queried documents from {collection.name}\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error querying documents: {e}\")\n",
    "            return None\n",
    "\n",
    "    def change_database_and_collection(self, new_database_name: str = None, new_collection_name: str = None) -> None:\n",
    "        \"\"\"Changes the database and/or collection to new specified names.\"\"\"\n",
    "        try:\n",
    "            # If test_mode is False, allow changing the database\n",
    "            if not self.test_mode and new_database_name:\n",
    "                self.db = self.client[new_database_name]\n",
    "                logging.info(f\"Database changed to: {self.db.name}\")\n",
    "\n",
    "            # Change collection if new_collection_name is provided\n",
    "            if new_collection_name:\n",
    "                self.collection = self.db[new_collection_name]\n",
    "                logging.info(f\"Collection changed to: {self.collection.name}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error changing database and/or collection: {e}\")\n",
    "\n",
    "    def close_connection(self) -> None:\n",
    "        \"\"\"Closes the connection to MongoDB.\"\"\"\n",
    "        try:\n",
    "            self.client.close()\n",
    "            logging.info(\"MongoDB connection closed.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error closing MongoDB connection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, List\n",
    "from pymongo import ASCENDING\n",
    "\n",
    "\n",
    "class QualifiedService:\n",
    "    def __init__(self, mdb_client: MongoDBClient):\n",
    "        \"\"\"\n",
    "        Initializes the QualifiedService with a MongoDBClient instance.\n",
    "\n",
    "        Args:\n",
    "            mdb_client (MongoDBClient): An instance of MongoDBClient.\n",
    "        \"\"\"\n",
    "        self.mdb_client = mdb_client\n",
    "\n",
    "    def get_place_of_work_count_grouped_by_role_and_state(\n",
    "            self, country: str, state: str, role: str\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Queries the 'qualified' collection to get the count of 'place_of_work' grouped\n",
    "        for a specific country, state, and role.\n",
    "\n",
    "        Args:\n",
    "            country (str): The country to filter by.\n",
    "            state (str): The state to filter by.\n",
    "            role (str): The role to filter by.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: A list of dictionaries containing the count of 'place_of_work' occurrences.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Use the change_database_and_collection method to switch to the 'qualified' collection\n",
    "            self.mdb_client.change_database_and_collection(new_collection_name=\"qualified\")\n",
    "            # Construct the match query\n",
    "            match_query = {\n",
    "                \"country\": country,\n",
    "                \"state\": state,\n",
    "                \"role\": role\n",
    "            }\n",
    "\n",
    "            # Perform aggregation to group and count only by 'place_of_work'\n",
    "            pipeline = [\n",
    "                {\"$match\": match_query},\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                        \"_id\": \"$place_of_work\",\n",
    "                        \"count\": {\"$sum\": 1}\n",
    "                    }\n",
    "                },\n",
    "                {\"$sort\": {\"count\": ASCENDING}}  # Sort by count in ascending order\n",
    "            ]\n",
    "\n",
    "            # Use the aggregate method from the MongoDB client\n",
    "            results = self.mdb_client.collection.aggregate(pipeline)\n",
    "            grouped_data = [doc for doc in results]\n",
    "\n",
    "            logging.info(f\"Queried and grouped data for country: {country}, state: {state}, role: {role}\")\n",
    "            return grouped_data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error querying and grouping data: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_bigram_data_by_country_state_role(\n",
    "            self, country: str, state: str, role: str\n",
    "    ) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"\n",
    "        Queries the 'bigram' collection to get tools, libraries, skills, and languages\n",
    "        for a specific country, state, and role.\n",
    "\n",
    "        Args:\n",
    "            country (str): The country to filter by.\n",
    "            state (str): The state to filter by.\n",
    "            role (str): The role to filter by.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[Dict]]: A dictionary containing tools, libraries, skills, and languages data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Use the change_database_and_collection method to switch to the 'bigram' collection\n",
    "            self.mdb_client.change_database_and_collection(new_collection_name=\"bigrams\")\n",
    "\n",
    "            # Construct the query\n",
    "            query = {\n",
    "                \"country\": country,\n",
    "                \"state\": state,\n",
    "                \"role\": role\n",
    "            }\n",
    "\n",
    "            # Specify the projection to include only the desired fields\n",
    "            projection = {\n",
    "                \"tools\": 1,\n",
    "                \"libraries\": 1,\n",
    "                \"skills\": 1,\n",
    "                \"languages\": 1,\n",
    "                \"_id\": 0  # Exclude the _id field if not needed\n",
    "            }\n",
    "\n",
    "            # Query the 'bigram' collection with the projection\n",
    "            result = self.mdb_client.query_documents(query, projection)\n",
    "            document = next(result, None)  # Get the first document if available\n",
    "\n",
    "            if document:\n",
    "                tools = document.get(\"tools\", [])\n",
    "                libraries = document.get(\"libraries\", [])\n",
    "                skills = document.get(\"skills\", [])\n",
    "                languages = document.get(\"languages\", [])\n",
    "\n",
    "                logging.info(f\"Fetched bigram data for country: {country}, state: {state}, role: {role}\")\n",
    "                return {\n",
    "                    \"tools\": tools,\n",
    "                    \"libraries\": libraries,\n",
    "                    \"skills\": skills,\n",
    "                    \"languages\": languages\n",
    "                }\n",
    "            else:\n",
    "                logging.info(f\"No bigram data found for country: {country}, state: {state}, role: {role}\")\n",
    "                return {\"tools\": [], \"libraries\": [], \"skills\": [], \"languages\": []}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error querying bigram data: {e}\")\n",
    "            return {\"tools\": [], \"libraries\": [], \"skills\": [], \"languages\": []}\n",
    "\n",
    "    def get_education_data_by_country_state_role(\n",
    "            self, country: str, state: str, role: str\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Queries the 'bigram' collection to get the education data\n",
    "        for a specific country, state, and role.\n",
    "\n",
    "        Args:\n",
    "            country (str): The country to filter by.\n",
    "            state (str): The state to filter by.\n",
    "            role (str): The role to filter by.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: A list containing education data. Returns an empty list if no data is found.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Use the change_database_and_collection method to switch to the 'bigram' collection\n",
    "            self.mdb_client.change_database_and_collection(new_collection_name=\"bigrams\")\n",
    "\n",
    "            # Construct the query\n",
    "            query = {\n",
    "                \"country\": country,\n",
    "                \"state\": state,\n",
    "                \"role\": role\n",
    "            }\n",
    "\n",
    "            # Specify the projection to include only the 'education' field\n",
    "            projection = {\n",
    "                \"education\": 1,\n",
    "                \"_id\": 0  # Exclude the _id field if not needed\n",
    "            }\n",
    "\n",
    "            # Query the 'bigram' collection with the projection\n",
    "            result = self.mdb_client.query_documents(query, projection)\n",
    "            document = next(result, None)  # Get the first document if available\n",
    "\n",
    "            if document:\n",
    "                education = document.get(\"education\", [])\n",
    "                logging.info(f\"Fetched education data for country: {country}, state: {state}, role: {role}\")\n",
    "                return education\n",
    "            else:\n",
    "                logging.info(f\"No education data found for country: {country}, state: {state}, role: {role}\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error querying education data: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_freq_grouped_by_state(self, country: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Queries the 'qualified' collection to count the number of records grouped by state\n",
    "        for a specific country, excluding the state \"ALL\".\n",
    "\n",
    "        Args:\n",
    "            country (str): The country to filter by.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: A list of dictionaries containing state and count of records, excluding the state \"ALL\".\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Use the change_database_and_collection method to switch to the 'qualified' collection\n",
    "            self.mdb_client.change_database_and_collection(new_collection_name=\"qualified\")\n",
    "\n",
    "            # Construct the match query to filter by country and exclude the state \"All\"\n",
    "            match_query = {\n",
    "                \"country\": country,\n",
    "                \"state\": {\"$ne\": \"All\"}  # Exclude the state \"All\"\n",
    "            }\n",
    "\n",
    "            # Perform aggregation to group by state and count the number of records\n",
    "            pipeline = [\n",
    "                {\"$match\": match_query},\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                        \"_id\": \"$state\",\n",
    "                        \"count\": {\"$sum\": 1}\n",
    "                    }\n",
    "                },\n",
    "                {\"$sort\": {\"count\": -1}}  # Sort by count in descending order\n",
    "            ]\n",
    "\n",
    "            # Use the aggregate method from the MongoDB client\n",
    "            results = self.mdb_client.collection.aggregate(pipeline)\n",
    "            grouped_data = [{\"state\": doc[\"_id\"], \"count\": doc[\"count\"]} for doc in results]\n",
    "\n",
    "            logging.info(f\"Fetched record count grouped by state for country: {country}, excluding state: ALL\")\n",
    "            return grouped_data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error querying record count grouped by state: {e}\")\n",
    "            return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_uri = \"mongodb+srv://nkalpam:nkalpam123@linkedinjobs.92q9w.mongodb.net/?retryWrites=true&w=majority&appName=LinkedinJobs\"\n",
    "database_name =\"linkedindb_prod\"\n",
    "collection_raw = \"clean\"\n",
    "test_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mongo_client = MongoDBClient(\n",
    "    uri=mongo_uri,\n",
    "    database_name=database_name,\n",
    "    collection_name=collection_raw,\n",
    "    test_mode=test_mode\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = QualifiedService(mongo_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "powData = qs.get_place_of_work_count_grouped_by_role_and_state(country=\"United States\",state= \"All\",role= \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "usaFreq = qs.get_freq_grouped_by_state(country=\"United States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramsData = qs.get_bigram_data_by_country_state_role(country=\"United States\",state= \"All\",role= \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tools': [{'bigram': ['microsoft', 'office'], 'score': 8},\n",
       "  {'bigram': ['publisher', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['power', 'bi'], 'score': 210},\n",
       "  {'bigram': ['bi', 'tableau'], 'score': 8},\n",
       "  {'bigram': ['powerbi', 'tableau'], 'score': 6},\n",
       "  {'bigram': ['salesforce', 'marketing'], 'score': 2},\n",
       "  {'bigram': ['g', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['tableau', 'power'], 'score': 21},\n",
       "  {'bigram': ['like', 'tableau'], 'score': 4},\n",
       "  {'bigram': ['analytics', 'adobe'], 'score': 4},\n",
       "  {'bigram': ['adobe', 'google'], 'score': 3},\n",
       "  {'bigram': ['quicksight', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['server', 'postgresql'], 'score': 3},\n",
       "  {'bigram': ['postgresql', 'oracle'], 'score': 3},\n",
       "  {'bigram': ['adobe', 'analytics'], 'score': 9},\n",
       "  {'bigram': ['focus', 'mysql'], 'score': 4},\n",
       "  {'bigram': ['mysql', 'database'], 'score': 2},\n",
       "  {'bigram': ['using', 'tableau'], 'score': 5},\n",
       "  {'bigram': ['tableau', 'prep'], 'score': 2},\n",
       "  {'bigram': ['tableau', 'spotfire'], 'score': 2},\n",
       "  {'bigram': ['alteryx', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['salesforce', 'sfdc'], 'score': 2},\n",
       "  {'bigram': ['google', 'looker'], 'score': 4},\n",
       "  {'bigram': ['looker', 'studio'], 'score': 10},\n",
       "  {'bigram': ['mining', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['tableau', 'powerbi'], 'score': 8},\n",
       "  {'bigram': ['use', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['tableau', 'create'], 'score': 2},\n",
       "  {'bigram': ['microsoft', 'excel'], 'score': 10},\n",
       "  {'bigram': ['tableau', 'excel'], 'score': 4},\n",
       "  {'bigram': ['tool', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['spotfire', 'tableau'], 'score': 4},\n",
       "  {'bigram': ['tableau', 'domo'], 'score': 2},\n",
       "  {'bigram': ['looker', 'bi'], 'score': 2},\n",
       "  {'bigram': ['tool', 'looker'], 'score': 4},\n",
       "  {'bigram': ['tableau', 'alteryx'], 'score': 2},\n",
       "  {'bigram': ['bi', 'looker'], 'score': 2},\n",
       "  {'bigram': ['g', 'looker'], 'score': 2},\n",
       "  {'bigram': ['studio', 'tableau'], 'score': 4},\n",
       "  {'bigram': ['like', 'looker'], 'score': 2},\n",
       "  {'bigram': ['looker', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['databricks', 'dbt'], 'score': 2},\n",
       "  {'bigram': ['snowflake', 'databricks'], 'score': 3},\n",
       "  {'bigram': ['tableau', 'looker'], 'score': 2},\n",
       "  {'bigram': ['visualization', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['tableau', 'server'], 'score': 3}],\n",
       " 'libraries': [],\n",
       " 'skills': [{'bigram': ['machine', 'learning'], 'score': 120},\n",
       "  {'bigram': ['data', 'visualization'], 'score': 206},\n",
       "  {'bigram': ['project', 'management'], 'score': 12},\n",
       "  {'bigram': ['data', 'analysis'], 'score': 261},\n",
       "  {'bigram': ['data', 'mining'], 'score': 22},\n",
       "  {'bigram': ['epicor', 'erp'], 'score': 2},\n",
       "  {'bigram': ['erp', 'system'], 'score': 4},\n",
       "  {'bigram': ['programming', 'skill'], 'score': 2},\n",
       "  {'bigram': ['analysis', 'programming'], 'score': 2},\n",
       "  {'bigram': ['programming', 'technique'], 'score': 2},\n",
       "  {'bigram': ['customer', 'reporting'], 'score': 2},\n",
       "  {'bigram': ['server', 'reporting'], 'score': 2},\n",
       "  {'bigram': ['reporting', 'service'], 'score': 2},\n",
       "  {'bigram': ['data', 'modeling'], 'score': 34},\n",
       "  {'bigram': ['etl', 'processes'], 'score': 13},\n",
       "  {'bigram': ['analysis', 'reporting'], 'score': 12},\n",
       "  {'bigram': ['year', 'reporting'], 'score': 2},\n",
       "  {'bigram': ['reporting', 'data'], 'score': 2},\n",
       "  {'bigram': ['quantitative', 'analysis'], 'score': 2},\n",
       "  {'bigram': ['business', 'analysis'], 'score': 2},\n",
       "  {'bigram': ['statistical', 'analysis'], 'score': 30},\n",
       "  {'bigram': ['etl', 'pipeline'], 'score': 2},\n",
       "  {'bigram': ['knowledge', 'programming'], 'score': 12},\n",
       "  {'bigram': ['programming', 'scripting'], 'score': 12},\n",
       "  {'bigram': ['etl', 'process'], 'score': 4},\n",
       "  {'bigram': ['critical', 'thinking'], 'score': 4},\n",
       "  {'bigram': ['analytical', 'reasoning'], 'score': 4},\n",
       "  {'bigram': ['programming', 'language'], 'score': 10},\n",
       "  {'bigram': ['analytics', 'reporting'], 'score': 9},\n",
       "  {'bigram': ['data', 'reporting'], 'score': 4},\n",
       "  {'bigram': ['reporting', 'visualization'], 'score': 3},\n",
       "  {'bigram': ['sfdc', 'crm'], 'score': 2},\n",
       "  {'bigram': ['engineering', 'reporting'], 'score': 2},\n",
       "  {'bigram': ['analysis', 'etl'], 'score': 2},\n",
       "  {'bigram': ['etl', 'development'], 'score': 2},\n",
       "  {'bigram': ['reporting', 'workbench'], 'score': 2},\n",
       "  {'bigram': ['etl', 'summary'], 'score': 2},\n",
       "  {'bigram': ['data', 'integration'], 'score': 20},\n",
       "  {'bigram': ['dynamic', 'crm'], 'score': 4},\n",
       "  {'bigram': ['crm', 'erp'], 'score': 2},\n",
       "  {'bigram': ['data', 'retrieval'], 'score': 2},\n",
       "  {'bigram': ['reporting', 'solutions'], 'score': 2},\n",
       "  {'bigram': ['predictive', 'modeling'], 'score': 6},\n",
       "  {'bigram': ['sa', 'programming'], 'score': 6},\n",
       "  {'bigram': ['statistical', 'programming'], 'score': 4},\n",
       "  {'bigram': ['programming', 'support'], 'score': 2},\n",
       "  {'bigram': ['analysis', 'dashboarding'], 'score': 2},\n",
       "  {'bigram': ['dashboarding', 'reporting'], 'score': 2},\n",
       "  {'bigram': ['reporting', 'platform'], 'score': 2},\n",
       "  {'bigram': ['reporting', 'needs'], 'score': 2},\n",
       "  {'bigram': ['salesforce', 'crm'], 'score': 2},\n",
       "  {'bigram': ['data', 'validation'], 'score': 2},\n",
       "  {'bigram': ['cash', 'erp'], 'score': 2},\n",
       "  {'bigram': ['erp', 'order'], 'score': 2},\n",
       "  {'bigram': ['data', 'wrangling'], 'score': 2},\n",
       "  {'bigram': ['erp', 'platform'], 'score': 2},\n",
       "  {'bigram': ['crm', 'data'], 'score': 5},\n",
       "  {'bigram': ['sql', 'programming'], 'score': 2},\n",
       "  {'bigram': ['bi', 'reporting'], 'score': 4},\n",
       "  {'bigram': ['integration', 'etl'], 'score': 2},\n",
       "  {'bigram': ['sql', 'crm'], 'score': 2},\n",
       "  {'bigram': ['etl', 'tool'], 'score': 2},\n",
       "  {'bigram': ['reporting', 'development'], 'score': 2},\n",
       "  {'bigram': ['tracking', 'reporting'], 'score': 4},\n",
       "  {'bigram': ['data', 'storytelling'], 'score': 2}],\n",
       " 'languages': [{'bigram': ['utilizing', 'python'], 'score': 9},\n",
       "  {'bigram': ['python', 'data'], 'score': 27},\n",
       "  {'bigram': ['leveraging', 'python'], 'score': 11},\n",
       "  {'bigram': ['python', 'datadriven'], 'score': 8},\n",
       "  {'bigram': ['using', 'python'], 'score': 10},\n",
       "  {'bigram': ['management', 'python'], 'score': 4},\n",
       "  {'bigram': ['analyst', 'sql'], 'score': 2},\n",
       "  {'bigram': ['sql', 'developer'], 'score': 2},\n",
       "  {'bigram': ['sql', 'query'], 'score': 16},\n",
       "  {'bigram': ['sql', 'snowflake'], 'score': 6},\n",
       "  {'bigram': ['skill', 'python'], 'score': 2},\n",
       "  {'bigram': ['sql', 'python'], 'score': 34},\n",
       "  {'bigram': ['sql', 'data'], 'score': 7},\n",
       "  {'bigram': ['using', 'sql'], 'score': 6},\n",
       "  {'bigram': ['c', 'python'], 'score': 6},\n",
       "  {'bigram': ['sql', 'server'], 'score': 34},\n",
       "  {'bigram': ['excel', 'vba'], 'score': 2},\n",
       "  {'bigram': ['vba', 'sql'], 'score': 2},\n",
       "  {'bigram': ['proficiency', 'sql'], 'score': 2},\n",
       "  {'bigram': ['ssis', 'python'], 'score': 2},\n",
       "  {'bigram': ['python', 'powershell'], 'score': 2},\n",
       "  {'bigram': ['python', 'r'], 'score': 16},\n",
       "  {'bigram': ['bi', 'python'], 'score': 2},\n",
       "  {'bigram': ['software', 'r'], 'score': 2},\n",
       "  {'bigram': ['python', 'scripting'], 'score': 2},\n",
       "  {'bigram': ['r', 'python'], 'score': 9},\n",
       "  {'bigram': ['python', 'sas'], 'score': 2},\n",
       "  {'bigram': ['r', 'pycharm'], 'score': 2},\n",
       "  {'bigram': ['either', 'python'], 'score': 24},\n",
       "  {'bigram': ['python', 'andor'], 'score': 24},\n",
       "  {'bigram': ['andor', 'javascript'], 'score': 24},\n",
       "  {'bigram': ['python', 'sql'], 'score': 8},\n",
       "  {'bigram': ['microsoft', 'sql'], 'score': 8},\n",
       "  {'bigram': ['sql', 'alteryx'], 'score': 2},\n",
       "  {'bigram': ['scala', 'r'], 'score': 2},\n",
       "  {'bigram': ['sql', 'azure'], 'score': 2},\n",
       "  {'bigram': ['strong', 'sql'], 'score': 4},\n",
       "  {'bigram': ['sql', 'skill'], 'score': 4},\n",
       "  {'bigram': ['skill', 'java'], 'score': 2},\n",
       "  {'bigram': ['tableau', 'sql'], 'score': 3},\n",
       "  {'bigram': ['python', 'weekly'], 'score': 2},\n",
       "  {'bigram': ['use', 'sql'], 'score': 2},\n",
       "  {'bigram': ['sql', 'manipulate'], 'score': 2},\n",
       "  {'bigram': ['use', 'python'], 'score': 2},\n",
       "  {'bigram': ['sql', 'tableau'], 'score': 2},\n",
       "  {'bigram': ['bi', 'sql'], 'score': 4},\n",
       "  {'bigram': ['sql', 'sa'], 'score': 4},\n",
       "  {'bigram': ['complex', 'sql'], 'score': 2},\n",
       "  {'bigram': ['query', 'python'], 'score': 2},\n",
       "  {'bigram': ['python', 'script'], 'score': 2},\n",
       "  {'bigram': ['excel', 'sql'], 'score': 10},\n",
       "  {'bigram': ['proficient', 'sql'], 'score': 2},\n",
       "  {'bigram': ['sql', 'database'], 'score': 2},\n",
       "  {'bigram': ['r', 'spark'], 'score': 4},\n",
       "  {'bigram': ['spark', 'sql'], 'score': 4},\n",
       "  {'bigram': ['python', 'power'], 'score': 2},\n",
       "  {'bigram': ['sql', 'retool'], 'score': 2},\n",
       "  {'bigram': ['azure', 'sql'], 'score': 4},\n",
       "  {'bigram': ['python', 'crystal'], 'score': 4},\n",
       "  {'bigram': ['visual', 'basic'], 'score': 2},\n",
       "  {'bigram': ['via', 'sql'], 'score': 2},\n",
       "  {'bigram': ['alteryx', 'sql'], 'score': 2},\n",
       "  {'bigram': ['vba', 'advanced'], 'score': 2},\n",
       "  {'bigram': ['sa', 'python'], 'score': 2},\n",
       "  {'bigram': ['writing', 'sql'], 'score': 2},\n",
       "  {'bigram': ['language', 'sql'], 'score': 2},\n",
       "  {'bigram': ['sql', 'etc'], 'score': 2},\n",
       "  {'bigram': ['oracle', 'sql'], 'score': 2},\n",
       "  {'bigram': ['python', 'model'], 'score': 4},\n",
       "  {'bigram': ['snowflake', 'sql'], 'score': 2},\n",
       "  {'bigram': ['python', 'looker'], 'score': 2},\n",
       "  {'bigram': ['python', 'plus'], 'score': 2},\n",
       "  {'bigram': ['python', 'development'], 'score': 2},\n",
       "  {'bigram': ['sql', 'git'], 'score': 2},\n",
       "  {'bigram': ['java', 'data'], 'score': 2}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "educationData  = qs.get_education_data_by_country_state_role(country=\"United States\",state= \"All\",role= \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bigram': ['bachelor', 'degree'], 'score': 6},\n",
       " {'bigram': ['field', 'phd'], 'score': 2},\n",
       " {'bigram': ['degree', 'business'], 'score': 16},\n",
       " {'bigram': ['degree', 'management'], 'score': 4},\n",
       " {'bigram': ['similar', 'degree'], 'score': 4},\n",
       " {'bigram': ['intermediate', 'degree'], 'score': 2},\n",
       " {'bigram': ['degree', 'independence'], 'score': 2},\n",
       " {'bigram': ['master', 'degree'], 'score': 11},\n",
       " {'bigram': ['degree', 'preferably'], 'score': 2},\n",
       " {'bigram': ['degree', 'program'], 'score': 3},\n",
       " {'bigram': ['degree', 'relevant'], 'score': 2},\n",
       " {'bigram': ['degree', 'data'], 'score': 2},\n",
       " {'bigram': ['degree', 'environmental'], 'score': 2},\n",
       " {'bigram': ['degree', 'equivalent'], 'score': 2},\n",
       " {'bigram': ['degree', 'computer'], 'score': 4},\n",
       " {'bigram': ['cdd', 'edd'], 'score': 2},\n",
       " {'bigram': ['degree', 'year'], 'score': 2},\n",
       " {'bigram': ['advanced', 'degree'], 'score': 2},\n",
       " {'bigram': ['degree', 'plus'], 'score': 2}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "educationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_place_of_work_data(country: str, state: str, role: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes the place of work data and prepares it in the desired percentage format,\n",
    "    considering only the counts for 'Hybrid', 'On-Site', and 'Remote'.\n",
    "    If any of the categories are missing or have zero counts, 1 is added to each category\n",
    "    to balance the data and calculate percentages.\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "        state (str): The state to filter by.\n",
    "        role (str): The role to filter by.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries with the 'id', 'label', and 'value' (percentage) of each place of work.\n",
    "    \"\"\"\n",
    "    # Call the QualifiedService method to get raw data\n",
    "    raw_data = powData\n",
    "\n",
    "    # Convert the raw data to a dictionary for easier access\n",
    "    place_of_work_counts = {entry[\"_id\"]: entry[\"count\"] for entry in raw_data}\n",
    "\n",
    "    # Define the desired place of work labels\n",
    "    desired_labels = [\"Hybrid\", \"On-Site\", \"Remote\"]\n",
    "\n",
    "    # Initialize counts, adding 1 to each category to balance the data\n",
    "    balanced_counts = {label: place_of_work_counts.get(label, 0) + 1 for label in desired_labels}\n",
    "\n",
    "    # Calculate the total count after adding 1 to each category\n",
    "    total_count = sum(balanced_counts.values())\n",
    "\n",
    "    # Process the data to form percentages and match the desired format\n",
    "    processed_data = []\n",
    "    for label in desired_labels:\n",
    "        count = balanced_counts[label]\n",
    "        percentage = (count / total_count * 100) if total_count > 0 else 0\n",
    "        processed_data.append({\n",
    "            \"id\": label,\n",
    "            \"label\": label,\n",
    "            \"value\": round(percentage, 2)  # Round to 2 decimal places\n",
    "        })\n",
    "\n",
    "    logging.info(f\"Processed place of work data for country: {country}, state: {state}, role: {role}\")\n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'Hybrid', 'label': 'Hybrid', 'value': 30.65},\n",
       " {'id': 'On-Site', 'label': 'On-Site', 'value': 0.5},\n",
       " {'id': 'Remote', 'label': 'Remote', 'value': 68.84}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_place_of_work_data(country=\"United States\",state= \"All\",role= \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_frequency_data(country: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes the state frequency data and prepares it in the desired percentage format.\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries with the 'state' and 'percentage' for each state.\n",
    "    \"\"\"\n",
    "    # Call the QualifiedService method to get raw state frequency data\n",
    "    raw_state_data = usaFreq\n",
    "\n",
    "    # Calculate the total count of all state records\n",
    "    total_count = sum(entry[\"count\"] for entry in raw_state_data)\n",
    "\n",
    "    # Process the data to form percentages and match the desired format\n",
    "    processed_data = []\n",
    "    for entry in raw_state_data:\n",
    "        state = entry[\"state\"]\n",
    "        count = entry[\"count\"]\n",
    "        percentage = (count / total_count * 100) if total_count > 0 else 0\n",
    "        processed_data.append({\n",
    "            \"state\": state,\n",
    "            \"percentage\": round(percentage, 2)  # Round to 2 decimal places\n",
    "        })\n",
    "\n",
    "    # Sort the data by state for consistency\n",
    "    processed_data.sort(key=lambda x: x[\"state\"])\n",
    "\n",
    "    logging.info(f\"Processed state frequency data for country: {country}\")\n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 'AL', 'percentage': 1.11},\n",
       " {'state': 'AR', 'percentage': 0.6},\n",
       " {'state': 'AZ', 'percentage': 2.14},\n",
       " {'state': 'CA', 'percentage': 10.1},\n",
       " {'state': 'CO', 'percentage': 1.93},\n",
       " {'state': 'CT', 'percentage': 1.03},\n",
       " {'state': 'DC', 'percentage': 0.77},\n",
       " {'state': 'DE', 'percentage': 0.51},\n",
       " {'state': 'FL', 'percentage': 3.21},\n",
       " {'state': 'GA', 'percentage': 5.09},\n",
       " {'state': 'IA', 'percentage': 0.64},\n",
       " {'state': 'ID', 'percentage': 0.34},\n",
       " {'state': 'IL', 'percentage': 4.75},\n",
       " {'state': 'IN', 'percentage': 1.54},\n",
       " {'state': 'KS', 'percentage': 0.56},\n",
       " {'state': 'KY', 'percentage': 0.13},\n",
       " {'state': 'LA', 'percentage': 0.47},\n",
       " {'state': 'MA', 'percentage': 2.48},\n",
       " {'state': 'MD', 'percentage': 2.78},\n",
       " {'state': 'ME', 'percentage': 0.09},\n",
       " {'state': 'MI', 'percentage': 1.46},\n",
       " {'state': 'MN', 'percentage': 1.67},\n",
       " {'state': 'MO', 'percentage': 1.97},\n",
       " {'state': 'MS', 'percentage': 0.09},\n",
       " {'state': 'MT', 'percentage': 0.04},\n",
       " {'state': 'NC', 'percentage': 2.87},\n",
       " {'state': 'ND', 'percentage': 0.09},\n",
       " {'state': 'NE', 'percentage': 0.64},\n",
       " {'state': 'NH', 'percentage': 0.26},\n",
       " {'state': 'NJ', 'percentage': 4.97},\n",
       " {'state': 'NM', 'percentage': 0.17},\n",
       " {'state': 'NV', 'percentage': 0.56},\n",
       " {'state': 'NY', 'percentage': 4.41},\n",
       " {'state': 'OH', 'percentage': 4.2},\n",
       " {'state': 'OK', 'percentage': 0.86},\n",
       " {'state': 'OR', 'percentage': 0.81},\n",
       " {'state': 'PA', 'percentage': 1.8},\n",
       " {'state': 'RI', 'percentage': 0.34},\n",
       " {'state': 'SC', 'percentage': 0.86},\n",
       " {'state': 'SD', 'percentage': 0.04},\n",
       " {'state': 'TN', 'percentage': 1.54},\n",
       " {'state': 'TX', 'percentage': 21.06},\n",
       " {'state': 'UT', 'percentage': 0.86},\n",
       " {'state': 'VA', 'percentage': 3.98},\n",
       " {'state': 'WA', 'percentage': 2.23},\n",
       " {'state': 'WI', 'percentage': 1.54},\n",
       " {'state': 'WV', 'percentage': 0.34},\n",
       " {'state': 'WY', 'percentage': 0.09}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_state_frequency_data(country=\"United States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_frequency_data(country: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes the state frequency data and prepares it in the desired percentage format.\n",
    "    Merges the count for 'DC' into 'WA' (Washington).\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries with the 'state' and 'percentage' for each state.\n",
    "    \"\"\"\n",
    "    # Call the QualifiedService method to get raw state frequency data\n",
    "    raw_state_data = usaFreq\n",
    "\n",
    "    # Merge the count for 'DC' into 'WA'\n",
    "    state_counts = {}\n",
    "    for entry in raw_state_data:\n",
    "        state = entry[\"state\"]\n",
    "        count = entry[\"count\"]\n",
    "        \n",
    "        # Merge 'DC' into 'WA'\n",
    "        if state == \"DC\":\n",
    "            state = \"WA\"\n",
    "        \n",
    "        if state in state_counts:\n",
    "            state_counts[state] += count\n",
    "        else:\n",
    "            state_counts[state] = count\n",
    "\n",
    "    # Calculate the total count of all state records\n",
    "    total_count = sum(state_counts.values())\n",
    "\n",
    "    # Process the data to form percentages and match the desired format\n",
    "    processed_data = []\n",
    "    for state, count in state_counts.items():\n",
    "        percentage = (count / total_count * 100) if total_count > 0 else 0\n",
    "        processed_data.append({\n",
    "            \"state\": state,\n",
    "            \"percentage\": round(percentage, 2)  # Round to 2 decimal places\n",
    "        })\n",
    "\n",
    "    # Sort the data by state for consistency\n",
    "    processed_data.sort(key=lambda x: x[\"state\"])\n",
    "\n",
    "    logging.info(f\"Processed state frequency data for country: {country}\")\n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 'AL', 'percentage': 1.11},\n",
       " {'state': 'AR', 'percentage': 0.6},\n",
       " {'state': 'AZ', 'percentage': 2.14},\n",
       " {'state': 'CA', 'percentage': 10.1},\n",
       " {'state': 'CO', 'percentage': 1.93},\n",
       " {'state': 'CT', 'percentage': 1.03},\n",
       " {'state': 'DE', 'percentage': 0.51},\n",
       " {'state': 'FL', 'percentage': 3.21},\n",
       " {'state': 'GA', 'percentage': 5.09},\n",
       " {'state': 'IA', 'percentage': 0.64},\n",
       " {'state': 'ID', 'percentage': 0.34},\n",
       " {'state': 'IL', 'percentage': 4.75},\n",
       " {'state': 'IN', 'percentage': 1.54},\n",
       " {'state': 'KS', 'percentage': 0.56},\n",
       " {'state': 'KY', 'percentage': 0.13},\n",
       " {'state': 'LA', 'percentage': 0.47},\n",
       " {'state': 'MA', 'percentage': 2.48},\n",
       " {'state': 'MD', 'percentage': 2.78},\n",
       " {'state': 'ME', 'percentage': 0.09},\n",
       " {'state': 'MI', 'percentage': 1.46},\n",
       " {'state': 'MN', 'percentage': 1.67},\n",
       " {'state': 'MO', 'percentage': 1.97},\n",
       " {'state': 'MS', 'percentage': 0.09},\n",
       " {'state': 'MT', 'percentage': 0.04},\n",
       " {'state': 'NC', 'percentage': 2.87},\n",
       " {'state': 'ND', 'percentage': 0.09},\n",
       " {'state': 'NE', 'percentage': 0.64},\n",
       " {'state': 'NH', 'percentage': 0.26},\n",
       " {'state': 'NJ', 'percentage': 4.97},\n",
       " {'state': 'NM', 'percentage': 0.17},\n",
       " {'state': 'NV', 'percentage': 0.56},\n",
       " {'state': 'NY', 'percentage': 4.41},\n",
       " {'state': 'OH', 'percentage': 4.2},\n",
       " {'state': 'OK', 'percentage': 0.86},\n",
       " {'state': 'OR', 'percentage': 0.81},\n",
       " {'state': 'PA', 'percentage': 1.8},\n",
       " {'state': 'RI', 'percentage': 0.34},\n",
       " {'state': 'SC', 'percentage': 0.86},\n",
       " {'state': 'SD', 'percentage': 0.04},\n",
       " {'state': 'TN', 'percentage': 1.54},\n",
       " {'state': 'TX', 'percentage': 21.06},\n",
       " {'state': 'UT', 'percentage': 0.86},\n",
       " {'state': 'VA', 'percentage': 3.98},\n",
       " {'state': 'WA', 'percentage': 3.0},\n",
       " {'state': 'WI', 'percentage': 1.54},\n",
       " {'state': 'WV', 'percentage': 0.34},\n",
       " {'state': 'WY', 'percentage': 0.09}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_state_frequency_data(country=\"United States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_education_data(country: str, state: str, role: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes the education data to prepare it in a list of dictionaries format.\n",
    "    Groups the 1-grams from bigrams (ignoring the word 'degree') and sums the scores,\n",
    "    then converts the scores to percentages and returns the top 4.\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "        state (str): The state to filter by.\n",
    "        role (str): The role to filter by.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries containing 'id', 'label', and 'value' for the top 4 1-grams.\n",
    "    \"\"\"\n",
    "    # Call the QualifiedService method to get raw education data\n",
    "    raw_education_data = qs.get_education_data_by_country_state_role(country,state,role)\n",
    "\n",
    "    # Dictionary to accumulate scores for each 1-gram\n",
    "    education_scores = {}\n",
    "\n",
    "    # Process the raw data to extract and accumulate scores\n",
    "    for item in raw_education_data:\n",
    "        bigram = item.get(\"bigram\", [])\n",
    "        score = item.get(\"score\", 0)\n",
    "\n",
    "        for word in bigram:\n",
    "            if word.lower() != \"degree\":  # Ignore the word 'degree'\n",
    "                if word.lower() in education_scores:\n",
    "                    education_scores[word.lower()] += score\n",
    "                else:\n",
    "                    education_scores[word.lower()] = score\n",
    "\n",
    "    # Calculate the total score for all 1-grams\n",
    "    total_score = sum(education_scores.values())\n",
    "\n",
    "    # Convert accumulated scores into percentages and format as required\n",
    "    mockEducationData = [\n",
    "        {\n",
    "            \"id\": word.capitalize(),\n",
    "            \"label\": word.capitalize(),  # Capitalize for label formatting\n",
    "            \"value\": round((score / total_score * 100), 2) if total_score > 0 else 0  # Calculate percentage\n",
    "        }\n",
    "        for word, score in education_scores.items()\n",
    "    ]\n",
    "\n",
    "    # Sort the data by percentage in descending order and select the top 4\n",
    "    mockEducationData.sort(key=lambda x: x[\"value\"], reverse=True)\n",
    "    top_4_data = mockEducationData[:4]  # Get only the top 4 entries\n",
    "\n",
    "    logging.info(f\"Processed education data for country: {country}, state: {state}, role: {role}\")\n",
    "    return top_4_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'Business', 'label': 'Business', 'value': 21.05},\n",
       " {'id': 'Master', 'label': 'Master', 'value': 14.47},\n",
       " {'id': 'Bachelor', 'label': 'Bachelor', 'value': 7.89},\n",
       " {'id': 'Management', 'label': 'Management', 'value': 5.26}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_education_data(\"United States\", \"All\", \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "\n",
    "def process_tools_data(country: str, state: str, role: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes the tools data by extracting 1-grams from bigrams, accumulating scores,\n",
    "    and calculating percentages. Special handling for 'power' + 'bi' and Microsoft-related combinations.\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "        state (str): The state to filter by.\n",
    "        role (str): The role to filter by.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of tools with their percentages.\n",
    "    \"\"\"\n",
    "    raw_tools_data = qs.get_bigram_data_by_country_state_role(country, state, role).get('tools', [])\n",
    "    tools_scores = {}\n",
    "\n",
    "    for item in raw_tools_data:\n",
    "        bigram = item['bigram']\n",
    "        score = item['score']\n",
    "\n",
    "        # Check for special case: \"power\" + \"bi\" -> \"powerbi\"\n",
    "        if \"power\" in bigram and \"bi\" in bigram:\n",
    "            tools_scores[\"powerbi\"] = tools_scores.get(\"powerbi\", 0) + score\n",
    "        else:\n",
    "            for word in bigram:\n",
    "                if word.lower() == \"microsoft\":\n",
    "                    # Combine 'Microsoft' with the other word in the bigram\n",
    "                    combined_tool = f\"microsoft {bigram[1] if bigram[0].lower() == 'microsoft' else bigram[0]}\"\n",
    "                    tools_scores[combined_tool] = tools_scores.get(combined_tool, 0) + score\n",
    "                else:\n",
    "                    tools_scores[word.lower()] = tools_scores.get(word.lower(), 0) + score\n",
    "\n",
    "    # Calculate total score and convert to percentages\n",
    "    total_score = sum(tools_scores.values())\n",
    "    tools_data = [\n",
    "        {\"tool\": tool, \"percentage\": round((score / total_score * 100), 2) if total_score > 0 else 0}\n",
    "        for tool, score in tools_scores.items()\n",
    "    ]\n",
    "\n",
    "    # Sort and return the top 5\n",
    "    tools_data.sort(key=lambda x: x[\"percentage\"], reverse=True)\n",
    "    return tools_data[:5]\n",
    "\n",
    "def process_skills_data(country: str, state: str, role: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes the skills data by extracting bigrams, accumulating scores, and calculating percentages.\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "        state (str): The state to filter by.\n",
    "        role (str): The role to filter by.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of skills with their percentages.\n",
    "    \"\"\"\n",
    "    raw_skills_data = qs.get_bigram_data_by_country_state_role(country, state, role).get('skills', [])\n",
    "    skills_scores = {}\n",
    "\n",
    "    for item in raw_skills_data:\n",
    "        bigram = \" \".join(item['bigram'])  # Join bigram with a space\n",
    "        score = item['score']\n",
    "        skills_scores[bigram] = skills_scores.get(bigram, 0) + score\n",
    "\n",
    "    # Calculate total score and convert to percentages\n",
    "    total_score = sum(skills_scores.values())\n",
    "    skills_data = [\n",
    "        {\"skill\": skill, \"percentage\": round((score / total_score * 100), 2) if total_score > 0 else 0}\n",
    "        for skill, score in skills_scores.items()\n",
    "    ]\n",
    "\n",
    "    # Sort and return the top 5\n",
    "    skills_data.sort(key=lambda x: x[\"percentage\"], reverse=True)\n",
    "    return skills_data[:5]\n",
    "\n",
    "def process_languages_data(country: str, state: str, role: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes the languages data by extracting 1-grams, accumulating scores, and calculating percentages.\n",
    "    Ignores specific 1-grams as specified.\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "        state (str): The state to filter by.\n",
    "        role (str): The role to filter by.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of languages with their percentages.\n",
    "    \"\"\"\n",
    "    raw_languages_data = qs.get_bigram_data_by_country_state_role(country, state, role).get('languages', [])\n",
    "    languages_scores = {}\n",
    "\n",
    "    # Define 1-grams to ignore\n",
    "    ignored_1grams = {\"data\"}  # Add any other 1-grams you want to ignore\n",
    "\n",
    "    for item in raw_languages_data:\n",
    "        for word in item['bigram']:\n",
    "            if word.lower() not in ignored_1grams:  # Check if the word is not in the ignored list\n",
    "                score = item['score']\n",
    "                languages_scores[word.lower()] = languages_scores.get(word.lower(), 0) + score\n",
    "\n",
    "    # Calculate total score and convert to percentages\n",
    "    total_score = sum(languages_scores.values())\n",
    "    languages_data = [\n",
    "        {\"language\": language, \"percentage\": round((score / total_score * 100), 2) if total_score > 0 else 0}\n",
    "        for language, score in languages_scores.items()\n",
    "    ]\n",
    "\n",
    "    # Sort and return the top 5\n",
    "    languages_data.sort(key=lambda x: x[\"percentage\"], reverse=True)\n",
    "    return languages_data[:5]\n",
    "\n",
    "def process_libraries_data(country: str, state: str, role: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes the libraries data by extracting 1-grams, accumulating scores, and calculating percentages.\n",
    "    Special handling for \"spring\" + \"boot\" -> \"spring boot\".\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "        state (str): The state to filter by.\n",
    "        role (str): The role to filter by.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of libraries with their percentages.\n",
    "    \"\"\"\n",
    "    raw_libraries_data = qs.get_bigram_data_by_country_state_role(country, state, role).get('libraries', [])\n",
    "    libraries_scores = {}\n",
    "\n",
    "    for item in raw_libraries_data:\n",
    "        bigram = item['bigram']\n",
    "        score = item['score']\n",
    "\n",
    "        # Check for special case: \"spring\" + \"boot\" -> \"spring boot\"\n",
    "        if \"spring\" in bigram and \"boot\" in bigram:\n",
    "            libraries_scores[\"spring boot\"] = libraries_scores.get(\"spring boot\", 0) + score\n",
    "        else:\n",
    "            for word in bigram:\n",
    "                libraries_scores[word.lower()] = libraries_scores.get(word.lower(), 0) + score\n",
    "\n",
    "    # Calculate total score and convert to percentages\n",
    "    total_score = sum(libraries_scores.values())\n",
    "    libraries_data = [\n",
    "        {\"library\": library, \"percentage\": round((score / total_score * 100), 2) if total_score > 0 else 0}\n",
    "        for library, score in libraries_scores.items()\n",
    "    ]\n",
    "\n",
    "    # Sort and return the top 5\n",
    "    libraries_data.sort(key=lambda x: x[\"percentage\"], reverse=True)\n",
    "    return libraries_data[:5]\n",
    "\n",
    "def process_bigram_data(country: str, state: str, role: str) -> Dict[str, List[Dict]]:\n",
    "    \"\"\"\n",
    "    Calls all four processing methods and formats the data into the desired structure.\n",
    "\n",
    "    Args:\n",
    "        country (str): The country to filter by.\n",
    "        state (str): The state to filter by.\n",
    "        role (str): The role to filter by.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Dict]]: A dictionary containing processed data for skills, tools, libraries, and languages.\n",
    "    \"\"\"\n",
    "    # Call each method to get the processed data\n",
    "    skills_data = process_skills_data(country, state, role)\n",
    "    tools_data = process_tools_data(country, state, role)\n",
    "    libraries_data = process_libraries_data(country, state, role)\n",
    "    languages_data = process_languages_data(country, state, role)\n",
    "\n",
    "    # Format the data into the desired structure\n",
    "    mockData = {\n",
    "        \"skills\": [{\"skill\": item[\"skill\"], \"percentage\": item[\"percentage\"]} for item in skills_data],\n",
    "        \"tools\": [{\"tool\": item[\"tool\"], \"percentage\": item[\"percentage\"]} for item in tools_data],\n",
    "        \"libraries\": [{\"library\": item[\"library\"], \"percentage\": item[\"percentage\"]} for item in libraries_data],\n",
    "        \"languages\": [{\"language\": item[\"language\"], \"percentage\": item[\"percentage\"]} for item in languages_data]\n",
    "    }\n",
    "\n",
    "    logging.info(f\"Processed bigram data for country: {country}, state: {state}, role: {role}\")\n",
    "    return mockData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skills': [{'skill': 'data analysis', 'percentage': 28.84},\n",
       "  {'skill': 'data visualization', 'percentage': 22.76},\n",
       "  {'skill': 'machine learning', 'percentage': 13.26},\n",
       "  {'skill': 'data modeling', 'percentage': 3.76},\n",
       "  {'skill': 'statistical analysis', 'percentage': 3.31}],\n",
       " 'tools': [{'tool': 'powerbi', 'percentage': 39.58},\n",
       "  {'tool': 'tableau', 'percentage': 17.14},\n",
       "  {'tool': 'looker', 'percentage': 5.3},\n",
       "  {'tool': 'power', 'percentage': 3.71},\n",
       "  {'tool': 'adobe', 'percentage': 2.83}],\n",
       " 'libraries': [],\n",
       " 'languages': [{'language': 'python', 'percentage': 27.8},\n",
       "  {'language': 'sql', 'percentage': 24.15},\n",
       "  {'language': 'andor', 'percentage': 5.85},\n",
       "  {'language': 'r', 'percentage': 4.27},\n",
       "  {'language': 'server', 'percentage': 4.15}]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_bigram_data(\"United States\", \"All\", \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tool': 'powerbi', 'percentage': 39.58},\n",
       " {'tool': 'tableau', 'percentage': 17.14},\n",
       " {'tool': 'looker', 'percentage': 5.3},\n",
       " {'tool': 'power', 'percentage': 3.71},\n",
       " {'tool': 'adobe', 'percentage': 2.83}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tools_data(\"United States\", \"All\", \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'language': 'python', 'percentage': 27.8},\n",
       " {'language': 'sql', 'percentage': 24.15},\n",
       " {'language': 'andor', 'percentage': 5.85},\n",
       " {'language': 'r', 'percentage': 4.27},\n",
       " {'language': 'server', 'percentage': 4.15}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_languages_data(\"United States\", \"All\", \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'skill': 'data analysis', 'percentage': 28.84},\n",
       " {'skill': 'data visualization', 'percentage': 22.76},\n",
       " {'skill': 'machine learning', 'percentage': 13.26},\n",
       " {'skill': 'data modeling', 'percentage': 3.76},\n",
       " {'skill': 'statistical analysis', 'percentage': 3.31}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_skills_data(\"United States\", \"All\", \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_libraries_data(\"United States\", \"NY\", \"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
